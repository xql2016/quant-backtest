"""
å·¥å…·2ï¼šç¼“å­˜è¦†ç›–åˆ¤æ–­å’Œæ¸…ç†å·¥å…·
åˆ¤æ–­ä¸€ä¸ªç¼“å­˜æ˜¯å¦å®Œå…¨è¦†ç›–å¦ä¸€ä¸ªï¼Œå¦‚æœæ˜¯åˆ™åˆ é™¤è¢«è¦†ç›–çš„ç¼“å­˜
"""

import pandas as pd
from pathlib import Path
from datetime import datetime, date
import sys
import json

sys.path.insert(0, str(Path(__file__).parent.parent))


class CacheOverlapTool:
    """ç¼“å­˜è¦†ç›–åˆ¤æ–­å·¥å…·"""
    
    def __init__(self, cache_root: str = "cache"):
        """
        åˆå§‹åŒ–è¦†ç›–å·¥å…·
        
        Args:
            cache_root: ç¼“å­˜æ ¹ç›®å½•
        """
        self.cache_root = Path(cache_root)
        self.data_dir = self.cache_root / "data"
        self.metadata_file = self.cache_root / "metadata" / "cache_index.json"
    
    def check_and_remove_covered(self, file1: str, file2: str, dry_run: bool = False) -> dict:
        """
        æ£€æŸ¥å¹¶åˆ é™¤è¢«è¦†ç›–çš„ç¼“å­˜
        
        Args:
            file1: ç¬¬ä¸€ä¸ªç¼“å­˜æ–‡ä»¶è·¯å¾„
            file2: ç¬¬äºŒä¸ªç¼“å­˜æ–‡ä»¶è·¯å¾„
            dry_run: æ˜¯å¦åªæ£€æŸ¥ä¸æ‰§è¡Œ
            
        Returns:
            ç»“æœå­—å…¸
        """
        print("=" * 80)
        print("ğŸ” ç¼“å­˜è¦†ç›–åˆ¤æ–­å·¥å…·")
        print("=" * 80)
        
        # 1. è§£ææ–‡ä»¶ä¿¡æ¯
        info1 = self._parse_cache_file(file1)
        info2 = self._parse_cache_file(file2)
        
        if not info1 or not info2:
            return {
                'status': 'error',
                'message': 'æ–‡ä»¶ä¿¡æ¯è§£æå¤±è´¥'
            }
        
        print(f"\nç¼“å­˜A: {info1['code']} ({info1['start_date']} ~ {info1['end_date']}) - {info1['file_size_mb']:.2f} MB")
        print(f"ç¼“å­˜B: {info2['code']} ({info2['start_date']} ~ {info2['end_date']}) - {info2['file_size_mb']:.2f} MB")
        
        # 2. éªŒè¯åŸºæœ¬ä¿¡æ¯ä¸€è‡´
        if not self._validate_same_asset(info1, info2):
            return {
                'status': 'error',
                'message': 'ä¸¤ä¸ªç¼“å­˜ä¸æ˜¯åŒä¸€ä¸ªèµ„äº§'
            }
        
        print("âœ… åŸºæœ¬ä¿¡æ¯éªŒè¯é€šè¿‡ï¼ˆåŒä¸€èµ„äº§ï¼‰")
        
        # 3. æ£€æŸ¥è¦†ç›–å…³ç³»
        coverage = self._check_coverage(info1, info2)
        
        print(f"\nğŸ“Š è¦†ç›–å…³ç³»åˆ†æ:")
        print(f"   å…³ç³»ç±»å‹: {coverage['type']}")
        print(f"   è¯´æ˜: {coverage['message']}")
        
        if coverage['type'] == 'no_coverage':
            return {
                'status': 'no_action',
                'message': 'ä¸¤ä¸ªç¼“å­˜æ— è¦†ç›–å…³ç³»ï¼Œæ— éœ€åˆ é™¤'
            }
        
        # 4. ç¡®å®šè¦åˆ é™¤çš„æ–‡ä»¶
        to_delete = coverage['covered_cache']
        to_keep = coverage['covering_cache']
        
        print(f"\nğŸ—‘ï¸  åˆ é™¤å†³ç­–:")
        print(f"   ä¿ç•™: {to_keep['filename']} ({to_keep['start_date']} ~ {to_keep['end_date']})")
        print(f"   åˆ é™¤: {to_delete['filename']} ({to_delete['start_date']} ~ {to_delete['end_date']})")
        print(f"   åŸå› : è¢«å®Œå…¨è¦†ç›–")
        
        if dry_run:
            print("\nğŸ” é¢„è§ˆæ¨¡å¼ï¼šä¸æ‰§è¡Œå®é™…åˆ é™¤")
            return {
                'status': 'preview',
                'message': 'é¢„è§ˆæˆåŠŸï¼Œä½¿ç”¨ dry_run=False æ‰§è¡Œå®é™…åˆ é™¤',
                'to_delete': to_delete['file_path'],
                'to_keep': to_keep['file_path']
            }
        
        # 5. æ‰§è¡Œåˆ é™¤
        print(f"\nğŸ”§ æ‰§è¡Œåˆ é™¤...")
        delete_result = self._delete_cache(to_delete)
        
        if delete_result['success']:
            print(f"âœ… åˆ é™¤æˆåŠŸ")
            print(f"   é‡Šæ”¾ç©ºé—´: {to_delete['file_size_mb']:.2f} MB")
            
            return {
                'status': 'success',
                'message': 'åˆ é™¤æˆåŠŸ',
                'deleted_file': to_delete['file_path'],
                'freed_space_mb': to_delete['file_size_mb']
            }
        else:
            return {
                'status': 'error',
                'message': f"åˆ é™¤å¤±è´¥: {delete_result['message']}"
            }
    
    def _parse_cache_file(self, file_path: str) -> dict:
        """ä»æ–‡ä»¶åè§£æç¼“å­˜ä¿¡æ¯"""
        try:
            file_path = Path(file_path)
            full_path = self.data_dir / file_path
            
            if not full_path.exists():
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
                return None
            
            # è§£æè·¯å¾„
            parts = file_path.parts
            data_source = parts[0]
            market = parts[1]
            filename = parts[-1]
            
            # è§£ææ–‡ä»¶å
            name_parts = Path(filename).stem.split('_')
            code = name_parts[0]
            start_date_str = name_parts[1]
            end_date_str = name_parts[2]
            interval = name_parts[3] if len(name_parts) > 3 else '1d'
            
            # è½¬æ¢æ—¥æœŸ
            start_date = datetime.strptime(start_date_str, '%Y%m%d').date()
            end_date = datetime.strptime(end_date_str, '%Y%m%d').date()
            
            # æ–‡ä»¶å¤§å°
            file_size_mb = full_path.stat().st_size / (1024 * 1024)
            
            return {
                'file_path': str(file_path),
                'full_path': full_path,
                'data_source': data_source,
                'market': market,
                'code': code,
                'start_date': start_date,
                'end_date': end_date,
                'interval': interval,
                'filename': filename,
                'file_size_mb': file_size_mb
            }
            
        except Exception as e:
            print(f"âŒ è§£ææ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _validate_same_asset(self, info1: dict, info2: dict) -> bool:
        """éªŒè¯æ˜¯å¦æ˜¯åŒä¸€èµ„äº§"""
        return (info1['data_source'] == info2['data_source'] and
                info1['market'] == info2['market'] and
                info1['code'] == info2['code'] and
                info1['interval'] == info2['interval'])
    
    def _check_coverage(self, info1: dict, info2: dict) -> dict:
        """
        æ£€æŸ¥è¦†ç›–å…³ç³»
        
        Returns:
            {
                'type': 'full_coverage' | 'partial_coverage' | 'no_coverage',
                'message': str,
                'covering_cache': è¦†ç›–è€…çš„info,
                'covered_cache': è¢«è¦†ç›–è€…çš„info
            }
        """
        # æ£€æŸ¥ info1 æ˜¯å¦å®Œå…¨è¦†ç›– info2
        if info1['start_date'] <= info2['start_date'] and info1['end_date'] >= info2['end_date']:
            return {
                'type': 'full_coverage',
                'message': f"ç¼“å­˜Aå®Œå…¨è¦†ç›–ç¼“å­˜B",
                'covering_cache': info1,
                'covered_cache': info2
            }
        
        # æ£€æŸ¥ info2 æ˜¯å¦å®Œå…¨è¦†ç›– info1
        if info2['start_date'] <= info1['start_date'] and info2['end_date'] >= info1['end_date']:
            return {
                'type': 'full_coverage',
                'message': f"ç¼“å­˜Bå®Œå…¨è¦†ç›–ç¼“å­˜A",
                'covering_cache': info2,
                'covered_cache': info1
            }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†è¦†ç›–
        if (info1['start_date'] <= info2['end_date'] and info1['end_date'] >= info2['start_date']):
            return {
                'type': 'partial_coverage',
                'message': f"ä¸¤ä¸ªç¼“å­˜éƒ¨åˆ†é‡å ï¼Œä½†æ— å®Œå…¨è¦†ç›–å…³ç³»"
            }
        
        # æ— è¦†ç›–
        return {
            'type': 'no_coverage',
            'message': 'ä¸¤ä¸ªç¼“å­˜æ— è¦†ç›–å…³ç³»'
        }
    
    def _delete_cache(self, cache_info: dict) -> dict:
        """åˆ é™¤ç¼“å­˜æ–‡ä»¶å’Œç´¢å¼•"""
        try:
            # åˆ é™¤æ–‡ä»¶
            file_path = Path(cache_info['full_path'])
            if file_path.exists():
                file_path.unlink()
            
            # æ›´æ–°ç´¢å¼•
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
            
            # æŸ¥æ‰¾å¹¶åˆ é™¤å¯¹åº”çš„ç´¢å¼•æ¡ç›®
            to_remove = []
            for key, entry in index_data['entries'].items():
                if entry.get('file_path') == cache_info['file_path']:
                    to_remove.append(key)
            
            for key in to_remove:
                del index_data['entries'][key]
            
            # é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            if index_data['entries']:
                total_size = sum(e.get('file_size_kb', 0) for e in index_data['entries'].values()) / 1024
                created_times = [e['created_at'] for e in index_data['entries'].values() if 'created_at' in e]
                
                index_data['statistics'] = {
                    'total_entries': len(index_data['entries']),
                    'total_size_mb': round(total_size, 2),
                    'oldest_entry': min(created_times) if created_times else None,
                    'newest_entry': max(created_times) if created_times else None
                }
            else:
                index_data['statistics'] = {
                    'total_entries': 0,
                    'total_size_mb': 0.0,
                    'oldest_entry': None,
                    'newest_entry': None
                }
            
            index_data['last_update'] = datetime.now().isoformat()
            
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, indent=2, ensure_ascii=False)
            
            return {
                'success': True,
                'message': 'åˆ é™¤æˆåŠŸ'
            }
            
        except Exception as e:
            return {
                'success': False,
                'message': str(e)
            }


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import sys
    
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python check_cache_overlap.py <æ–‡ä»¶1> <æ–‡ä»¶2> [--dry-run]")
        print()
        print("ç¤ºä¾‹:")
        print("  python tools/check_cache_overlap.py \\")
        print("    tushare/a_stock/000001_20240101_20260101.parquet \\")
        print("    tushare/a_stock/000001_20250101_20260101.parquet")
        print()
        print("é¢„è§ˆæ¨¡å¼ï¼ˆä¸å®é™…æ‰§è¡Œï¼‰:")
        print("  python tools/check_cache_overlap.py <æ–‡ä»¶1> <æ–‡ä»¶2> --dry-run")
        sys.exit(1)
    
    file1 = sys.argv[1]
    file2 = sys.argv[2]
    dry_run = '--dry-run' in sys.argv
    
    tool = CacheOverlapTool()
    result = tool.check_and_remove_covered(file1, file2, dry_run=dry_run)
    
    print(f"\nç»“æœ: {result['status']}")
    print(f"ä¿¡æ¯: {result['message']}")


if __name__ == '__main__':
    main()
