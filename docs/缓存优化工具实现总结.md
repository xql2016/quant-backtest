# 缓存优化工具实现总结

## 概述

根据需求，我已经创建了三个缓存优化工具，放置在 `tools/` 文件夹中。这些工具可以自动化管理缓存数据，减少冗余，节省磁盘空间。

---

## 工具清单

### 1. **merge_continuous_caches.py** - 连续缓存合并工具

#### 功能
- 输入：两个缓存文件名
- 判断：两个缓存是否完全连续
- 操作：如果连续则合并，删除原缓存

#### 核心方法
```python
def merge_continuous_caches(file1: str, file2: str, dry_run: bool = False) -> dict
```

#### 连续性判断标准
1. **完全连续** (gap=1): A到2025-07-08，B从2025-07-09
2. **边界重叠** (gap=0): A到2025-07-08，B从2025-07-08
3. **多天重叠** (gap<0): A到2025-07-15，B从2025-07-10（重叠6天）
4. **存在缺口** (gap>1): 不合并，报错

#### 重叠处理策略
- 使用后一个缓存（B）的数据（认为是更新的数据）
- 自动去重
- 保持时间序列排序

#### 使用示例
```bash
# 预览模式
python tools/merge_continuous_caches.py \
  tushare/a_stock/000001_20250101_20250708.parquet \
  tushare/a_stock/000001_20250709_20260101.parquet \
  --dry-run

# 执行合并
python tools/merge_continuous_caches.py \
  tushare/a_stock/000001_20250101_20250708.parquet \
  tushare/a_stock/000001_20250709_20260101.parquet
```

---

### 2. **check_cache_overlap.py** - 缓存覆盖判断工具

#### 功能
- 输入：两个缓存文件名
- 判断：一个缓存是否完全覆盖另一个
- 操作：如果完全覆盖则删除被覆盖的缓存

#### 核心方法
```python
def check_and_remove_covered(file1: str, file2: str, dry_run: bool = False) -> dict
```

#### 覆盖关系判断
```python
# A 完全覆盖 B 的条件：
A.start_date <= B.start_date AND A.end_date >= B.end_date
```

示例：
- A缓存: 2024-01-01 ~ 2026-01-01 ✅ 覆盖
- B缓存: 2025-01-01 ~ 2025-12-31 ❌ 被覆盖（删除）

#### 决策逻辑
- **完全覆盖**: 删除被覆盖的缓存
- **部分覆盖**: 不删除，提示需要手动处理
- **无覆盖**: 不删除

#### 使用示例
```bash
# 预览模式
python tools/check_cache_overlap.py \
  tushare/a_stock/000001_20240101_20260101.parquet \
  tushare/a_stock/000001_20250101_20260101.parquet \
  --dry-run

# 执行清理
python tools/check_cache_overlap.py \
  tushare/a_stock/000001_20240101_20260101.parquet \
  tushare/a_stock/000001_20250101_20260101.parquet
```

---

### 3. **auto_optimize_cache.py** - 自动优化工具 ⭐

#### 功能
- 遍历 `cache/data/` 目录下的所有缓存
- 自动执行合并和清理操作
- 生成优化报告

#### 核心方法
```python
# 生成优化报告（只分析）
def get_optimization_report() -> dict

# 自动执行优化
def auto_optimize(dry_run: bool = True, 
                 enable_merge: bool = True, 
                 enable_cleanup: bool = True)
```

#### 工作流程

**阶段1：扫描**
- 遍历 `cache/data/` 目录
- 按资产分组：`{data_source}_{market}_{code}_{interval}`
- 按开始日期排序

**阶段2：清理被覆盖的缓存**
- 检查同一资产组内的所有缓存
- 找出覆盖关系
- 删除被覆盖的缓存
- 更新索引

**阶段3：合并连续的缓存**
- 检查同一资产组内的相邻缓存
- 判断是否连续（gap ≤ 1）
- 合并连续的缓存
- 删除原缓存
- 更新索引

**阶段4：生成报告**
- 删除的冗余缓存数量
- 合并的缓存对数量
- 释放的磁盘空间

#### 使用示例
```bash
# 生成优化报告（只分析，不执行）
python tools/auto_optimize_cache.py --report

# 预览模式（显示将要执行的操作）
python tools/auto_optimize_cache.py

# 执行优化
python tools/auto_optimize_cache.py --execute
```

#### 输出示例
```
================================================================================
📊 缓存优化分析报告
================================================================================

资产: tushare_a_stock_000001_1d
  缓存数量: 3
  ⚠️ 发现冗余: 000001_20250101_20260101.parquet 被 000001_20240101_20260101.parquet 覆盖
  💡 可合并: 000001_20240101_20241231.parquet + 000001_20250101_20251231.parquet (gap=1天)

================================================================================
📊 优化潜力总结
================================================================================
可删除冗余缓存: 5 个
可合并连续缓存: 3 对
可释放空间: 125.45 MB
```

---

## 技术实现细节

### 1. 文件名解析

所有工具都使用统一的文件名解析逻辑：

```python
文件路径: tushare/a_stock/000001_20250101_20251231_1d.parquet
解析结果:
  data_source: tushare
  market: a_stock
  code: 000001
  start_date: 2025-01-01
  end_date: 2025-12-31
  interval: 1d
```

### 2. 索引更新

所有操作都会自动更新 `cache/metadata/cache_index.json`：
- 删除旧缓存的索引条目
- 添加新缓存的索引条目
- 更新时间戳
- 保持索引一致性

### 3. 安全机制

#### 预览模式
- 所有工具都支持 `--dry-run` 参数
- 只检查和分析，不执行实际操作
- 显示将要执行的操作

#### 验证机制
- 检查文件是否存在
- 验证是否是同一资产（数据源、市场、代码、时间粒度）
- 检查日期连续性/覆盖关系
- 数据合并时自动去重

#### 幂等性
- 多次运行不会产生副作用
- 已删除的缓存不会重复删除
- 已合并的缓存不会重复合并

---

## 使用场景

### 场景1：定期自动优化（推荐）⭐

```bash
# 每周运行一次
python tools/auto_optimize_cache.py --execute
```

适用于：
- 定期清理冗余缓存
- 自动合并历史数据
- 节省磁盘空间

### 场景2：手动合并特定缓存

```bash
python tools/merge_continuous_caches.py \
  tushare/a_stock/000001_20250101_20250630.parquet \
  tushare/a_stock/000001_20250701_20251231.parquet
```

适用于：
- 明确知道哪两个缓存需要合并
- 精细化控制合并操作

### 场景3：清理被覆盖的旧缓存

```bash
python tools/check_cache_overlap.py \
  tushare/a_stock/000001_20240101_20260101.parquet \
  tushare/a_stock/000001_20250101_20250630.parquet
```

适用于：
- 删除特定的冗余缓存
- 清理被覆盖的旧数据

---

## 完整工作流程示例

```bash
# 1. 查看当前缓存状态
python test/cache_tool.py --stats

# 输出:
# ============================================================
# 📊 缓存统计信息
# ============================================================
# 缓存条目数: 12
# 总大小: 456.78 MB
# 数据源分布:
#   - tushare: 8 个缓存, 345.67 MB
#   - akshare: 4 个缓存, 111.11 MB

# 2. 生成优化报告
python tools/auto_optimize_cache.py --report

# 输出:
# 可删除冗余缓存: 5 个
# 可合并连续缓存: 3 对
# 可释放空间: 125.45 MB

# 3. 预览优化操作
python tools/auto_optimize_cache.py

# 输出:
# [预览] 将删除: 000001_20250101_20260101.parquet (被覆盖)
# [预览] 将合并: 000001_20240101_20241231.parquet + 000001_20250101_20251231.parquet

# 4. 确认后执行优化
python tools/auto_optimize_cache.py --execute

# 输出:
# ✅ 删除: 000001_20250101_20260101.parquet
# ✅ 合并: 000001_20240101_20251231.parquet
# 🎉 优化完成！

# 5. 查看优化后的状态
python test/cache_tool.py --stats

# 输出:
# 缓存条目数: 7
# 总大小: 331.33 MB
# 释放空间: 125.45 MB
```

---

## 文件结构

```
quant-backtest/
├── tools/                           # 缓存优化工具目录
│   ├── README.md                    # 详细使用指南
│   ├── merge_continuous_caches.py   # 工具1: 连续缓存合并
│   ├── check_cache_overlap.py       # 工具2: 缓存覆盖判断
│   └── auto_optimize_cache.py       # 工具3: 自动优化
├── test/
│   ├── test_cache_tools.py          # 工具测试套件
│   └── test_tools_simple.py         # 简化测试
└── docs/
    └── 缓存优化工具实现总结.md       # 本文档
```

---

## 性能优化建议

### 1. 定期优化

建议每周运行一次自动优化：

```bash
# 添加到 crontab
0 3 * * 0 cd /path/to/quant-backtest && python tools/auto_optimize_cache.py --execute
```

### 2. 监控缓存大小

定期查看优化报告：

```bash
python tools/auto_optimize_cache.py --report
```

### 3. 合并策略

- 对于历史数据（>7天），建议尽量合并
- 对于近期数据（<7天），可能频繁更新，暂不合并
- 对于实时数据（当天），等待数据稳定后再合并

---

## 常见问题

### Q1: 合并后的文件如何命名？

A: 使用合并后的日期范围：
```
合并前: 000001_20250101_20250630.parquet + 000001_20250701_20251231.parquet
合并后: 000001_20250101_20251231.parquet
```

### Q2: 重叠部分的数据如何处理？

A: 使用后一个缓存的数据（认为是更新的）。

### Q3: 如果两个缓存中间有缺口怎么办？

A: 不会合并，会提示缺口天数。

### Q4: 工具会不会误删数据？

A: 不会。工具只在明确的覆盖关系下删除，且支持预览模式。

### Q5: 可以撤销操作吗？

A: 工具本身不提供撤销，建议：
1. 使用预览模式确认
2. 操作前备份索引文件
3. 如需恢复，重新获取数据

---

## 未来改进方向

1. **增量合并**: 支持合并时填补小缺口（1-2天）
2. **并行处理**: 支持多线程/多进程优化
3. **智能策略**: 根据访问频率决定是否合并
4. **可视化**: 提供 Web UI 查看和管理缓存
5. **回滚功能**: 支持撤销最近的优化操作

---

## 总结

✅ **已实现的功能**：
- 两缓存连续判断和合并
- 缓存覆盖判断和清理
- 自动遍历和优化所有缓存
- 预览模式和报告生成
- 索引自动更新
- 安全验证机制

✅ **工具特点**：
- 幂等性：多次运行无副作用
- 安全性：预览模式、验证机制
- 易用性：命令行界面、详细输出
- 灵活性：可单独使用或自动化

✅ **应用价值**：
- 减少冗余缓存，节省磁盘空间
- 简化缓存管理，提高效率
- 自动化优化，减少人工干预
